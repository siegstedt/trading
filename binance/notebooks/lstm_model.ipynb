{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "changing-ribbon",
   "metadata": {},
   "source": [
    "# LSTM model for crypto prediction using Keras\n",
    "\n",
    "This tutorial illustrates how to get started forecasting time series with LSTM models. Stock market data is a great choice for this because it’s quite regular and widely available to everyone. Please don’t take this as financial advice or use it to make any trades of your own.\n",
    "\n",
    "We will build a LSTM model to predict crypto price.\n",
    "\n",
    "You will learn:\n",
    "\n",
    "- How to transform a raw dataset into something we can use for time series forecasting.\n",
    "- How to prepare data and fit an LSTM for a multivariate time series forecasting problem.\n",
    "- How to make a forecast and rescale the result back into the original units.\n",
    "\n",
    "Reference for how to build a LSTM model for stock market prediction:\n",
    "* https://www.datacamp.com/community/tutorials/lstm-python-stock-market\n",
    "* https://www.kdnuggets.com/2018/11/keras-long-short-term-memory-lstm-model-predict-stock-prices.html\n",
    "\n",
    "Reference for how to build a multivariate time series forecasting with LSTM:\n",
    "* https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "* https://www.analyticsvidhya.com/blog/2020/10/multivariate-multi-step-time-series-forecasting-using-stacked-lstm-sequence-to-sequence-autoencoder-in-tensorflow-2-0-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "young-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.2.3\n",
      "json: 2.0.9\n",
      "numpy: 1.19.5\n"
     ]
    }
   ],
   "source": [
    "# load required packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(f'pandas: {pd.__version__}')\n",
    "print(f'json: {json.__version__}')\n",
    "print(f'numpy: {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eight-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# libraries for lstm model (with tensorflow)\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(f'tensorflow: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-green",
   "metadata": {},
   "source": [
    "## Basic data preparation\n",
    "\n",
    "With this exercise, we will work with **hourly** ticker data for **ETHEUR**. The data was extracted from the Binance API (see the notebook \"hist_data_from_binance.ipynb\". For reasons of convenience, we will simply load the csv file generated through the other notebook.\n",
    "\n",
    "The data spans over more than 10,000 data points for a total time of a little more than a year: from 2020-01-03 to 2021-02-28. We have open, high, low, close, volume available for every hour of the days included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "drawn-mozambique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/siegstedt/projects/trading/binance/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "coral-championship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10125 rows and 5 cols.\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "filepath = '/home/siegstedt/projects/trading/binance/data/etheur_2020-01_2021-02_1h.csv'\n",
    "data = pd.read_csv(filepath, index_col=0, header=0).drop(columns=[\"datetime\"])\n",
    "data.index.name = \"datetime\"\n",
    "print(f\"Loaded {data.shape[0]} rows and {data.shape[1]} cols.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "instrumental-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        open     high      low    close      volume\n",
      "datetime                                                           \n",
      "2020-01-03 09:00:00    113.8    115.4    113.8    115.4      1.1027\n",
      "2020-01-03 10:00:00   118.46   118.46   118.46   118.46         0.5\n",
      "2020-01-03 11:00:00   118.06   118.06   118.02   118.02     1.33288\n",
      "2020-01-03 12:00:00    118.4    118.4    118.4    118.4     0.08539\n",
      "2020-01-03 13:00:00    118.4    118.4    118.4    118.4         0.0\n",
      "...                      ...      ...      ...      ...         ...\n",
      "2021-02-28 19:00:00  1104.73   1128.1   1100.5  1121.05  2268.75758\n",
      "2021-02-28 20:00:00  1121.19  1159.63  1119.37   1156.0  2217.30903\n",
      "2021-02-28 21:00:00  1155.49   1175.4  1150.55   1170.4  2530.15172\n",
      "2021-02-28 22:00:00  1170.29  1183.28  1163.42   1175.0  2801.53662\n",
      "2021-02-28 23:00:00   1175.0  1180.97  1156.75  1179.39  1292.76135\n"
     ]
    }
   ],
   "source": [
    "# data inspection\n",
    "head = data.head(5)\n",
    "tail = data.tail(5)\n",
    "mid = pd.DataFrame({\"...\":[\"...\" for i in data.columns]}).transpose()\n",
    "mid.columns = data.columns\n",
    "preview = pd.concat([head, mid, tail])\n",
    "preview.index.name = data.index.name\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "alone-court",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-aa1323fe3069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \"\"\"\n\u001b[1;32m    353\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     41\u001b[0m             display(\n\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         ticksLight = _is_light([label.get_color()\n\u001b[0m\u001b[1;32m    181\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                                 for label in axis.get_ticklabels()])\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mticksLight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# there are one or more tick labels, all with the same lightness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_ticklabels\u001b[0;34m(self, minor, which)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklabels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return this Axis' major tick labels, as a list of `~.text.Text`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mlabels1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;31m# Update the new tick label properties from the old.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m             \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_tick_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mXTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m         )\n\u001b[1;32m    442\u001b[0m         \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text2_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         self.label2.set(\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mverticalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmove_color_to_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfindobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Update bbox last, as it depends on font properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/yes/envs/trading/lib/python3.8/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meventson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m                     _api.warn_deprecated(\n\u001b[1;32m   1051\u001b[0m                         \u001b[0;34m\"3.3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Case-insensitive properties were \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# specify columns to plot\n",
    "groups = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "i = 1\n",
    "# plot each column\n",
    "plt.figure(figsize=(20,10))\n",
    "for group in groups:\n",
    "    plt.subplot(len(groups), 1, i)\n",
    "    plt.plot(data.loc[:, group])\n",
    "    plt.title(group, y=1, loc='center')\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-potential",
   "metadata": {},
   "source": [
    "### LSTM Data Preparation\n",
    "\n",
    "The first step is to prepare the pollution dataset for the LSTM.\n",
    "\n",
    "This involves framing the dataset as a supervised learning problem and normalizing the input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-hollywood",
   "metadata": {},
   "source": [
    "We will frame the supervised learning problem as **predicting the closing price at the current hour (t)** given the market conditions (e.g. open, high, low, volume) at the prior time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-freeze",
   "metadata": {},
   "source": [
    "Some alternate formulations you could explore include:\n",
    "\n",
    "- Predict the closing price for the next hour based on the market conditions over the last 24 hours.\n",
    "- Predict the closing price for the next hour as above and given the “expected” market conditions for the next hour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-corporation",
   "metadata": {},
   "source": [
    "#### Convert multivariate \n",
    "\n",
    "We can transform the dataset using the series_to_supervised() function.\n",
    "\n",
    "First, the “pollution.csv” dataset is loaded. The wind direction feature is label encoded (integer encoded). This could further be one-hot encoded in the future if you are interested in exploring it.\n",
    "\n",
    "Next, all features are normalized, then the dataset is transformed into a supervised learning problem. The weather variables for the hour to be predicted (t) are then removed.\n",
    "\n",
    "Reference:\n",
    "https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "polar-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "moved-binding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var4(t)\n",
      "1   0.016525   0.013103   0.022112   0.016970   0.000058  0.018900\n",
      "2   0.019463   0.015033   0.025041   0.018900   0.000026  0.018622\n",
      "3   0.019211   0.014780   0.024765   0.018622   0.000070  0.018862\n",
      "4   0.019425   0.014995   0.025003   0.018862   0.000004  0.018862\n",
      "5   0.019425   0.014995   0.025003   0.018862   0.000000  0.018862\n"
     ]
    }
   ],
   "source": [
    "values = data.values\n",
    "# ensure that all values are floats\n",
    "values = values.astype('float64')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed = reframed.drop(columns=['var1(t)','var2(t)','var3(t)','var5(t)',])\n",
    "print(reframed.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-language",
   "metadata": {},
   "source": [
    "Running the example prints the first 5 rows of the transformed dataset. We can see the 5 input variables (input series) and the 1 output variable (close price at the current hour)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-cylinder",
   "metadata": {},
   "source": [
    "This data preparation is simple and there is more we could explore. Some ideas you could look at include:\n",
    "\n",
    "- Making all series stationary with differencing and seasonal adjustment.\n",
    "- Providing more than 1 hour of input time steps.\n",
    "\n",
    "This last point is perhaps the most important given the use of Backpropagation through time by LSTMs when learning sequence prediction problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-turner",
   "metadata": {},
   "source": [
    "### Train test split\n",
    "\n",
    "First, we must split the prepared dataset into train and test sets. To speed up the training of the model for this demonstration, we will only fit the model on the first half year of data, then evaluate it on the remaining half years of data. If you have time, consider exploring the inverted version of this test harness.\n",
    "\n",
    "The example below splits the dataset into train and test sets, then splits the train and test sets into input and output variables. Finally, the inputs (X) are reshaped into the 3D format expected by LSTMs, namely [samples, timesteps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "recent-costs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 1, 5) (4320,) (5804, 1, 5) (5804,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 180 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-coach",
   "metadata": {},
   "source": [
    "### Define and fit the model\n",
    "\n",
    "Now we can define and fit our LSTM model.\n",
    "\n",
    "We will define the LSTM with 50 neurons in the first hidden layer and 1 neuron in the output layer for predicting pollution. The input shape will be 1 time step with 8 features.\n",
    "\n",
    "We will use the Mean Absolute Error (MAE) loss function and the efficient Adam version of stochastic gradient descent.\n",
    "\n",
    "The model will be fit for 50 training epochs with a batch size of 72. Remember that the internal state of the LSTM in Keras is reset at the end of each batch, so an internal state that is a function of a number of days may be helpful (try testing this).\n",
    "\n",
    "Finally, we keep track of both the training and test loss during training by setting the validation_data argument in the fit() function. At the end of the run both the training and test loss are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sweet-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "expensive-collaboration",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60/60 - 1s - loss: 0.0199 - val_loss: 0.1425\n",
      "Epoch 2/50\n",
      "60/60 - 0s - loss: 0.0176 - val_loss: 0.1066\n",
      "Epoch 3/50\n",
      "60/60 - 0s - loss: 0.0149 - val_loss: 0.0845\n",
      "Epoch 4/50\n",
      "60/60 - 0s - loss: 0.0116 - val_loss: 0.0717\n",
      "Epoch 5/50\n",
      "60/60 - 0s - loss: 0.0101 - val_loss: 0.0455\n",
      "Epoch 6/50\n",
      "60/60 - 0s - loss: 0.0072 - val_loss: 0.0282\n",
      "Epoch 7/50\n",
      "60/60 - 0s - loss: 0.0048 - val_loss: 0.0100\n",
      "Epoch 8/50\n",
      "60/60 - 0s - loss: 0.0023 - val_loss: 0.0286\n",
      "Epoch 9/50\n",
      "60/60 - 0s - loss: 0.0050 - val_loss: 0.0153\n",
      "Epoch 10/50\n",
      "60/60 - 0s - loss: 0.0036 - val_loss: 0.0214\n",
      "Epoch 11/50\n",
      "60/60 - 0s - loss: 0.0044 - val_loss: 0.0149\n",
      "Epoch 12/50\n",
      "60/60 - 0s - loss: 0.0035 - val_loss: 0.0200\n",
      "Epoch 13/50\n",
      "60/60 - 0s - loss: 0.0044 - val_loss: 0.0108\n",
      "Epoch 14/50\n",
      "60/60 - 0s - loss: 0.0028 - val_loss: 0.0272\n",
      "Epoch 15/50\n",
      "60/60 - 0s - loss: 0.0048 - val_loss: 0.0143\n",
      "Epoch 16/50\n",
      "60/60 - 0s - loss: 0.0030 - val_loss: 0.0247\n",
      "Epoch 17/50\n",
      "60/60 - 0s - loss: 0.0045 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "60/60 - 0s - loss: 0.0016 - val_loss: 0.0243\n",
      "Epoch 19/50\n",
      "60/60 - 0s - loss: 0.0035 - val_loss: 0.0192\n",
      "Epoch 20/50\n",
      "60/60 - 0s - loss: 0.0037 - val_loss: 0.0237\n",
      "Epoch 21/50\n",
      "60/60 - 0s - loss: 0.0038 - val_loss: 0.0235\n",
      "Epoch 22/50\n",
      "60/60 - 0s - loss: 0.0037 - val_loss: 0.0244\n",
      "Epoch 23/50\n",
      "60/60 - 0s - loss: 0.0037 - val_loss: 0.0246\n",
      "Epoch 24/50\n",
      "60/60 - 0s - loss: 0.0037 - val_loss: 0.0244\n",
      "Epoch 25/50\n",
      "60/60 - 0s - loss: 0.0035 - val_loss: 0.0265\n",
      "Epoch 26/50\n",
      "60/60 - 0s - loss: 0.0036 - val_loss: 0.0268\n",
      "Epoch 27/50\n",
      "60/60 - 0s - loss: 0.0035 - val_loss: 0.0265\n",
      "Epoch 28/50\n",
      "60/60 - 0s - loss: 0.0034 - val_loss: 0.0292\n",
      "Epoch 29/50\n",
      "60/60 - 0s - loss: 0.0036 - val_loss: 0.0282\n",
      "Epoch 30/50\n",
      "60/60 - 0s - loss: 0.0034 - val_loss: 0.0282\n",
      "Epoch 31/50\n",
      "60/60 - 0s - loss: 0.0033 - val_loss: 0.0314\n",
      "Epoch 32/50\n",
      "60/60 - 0s - loss: 0.0035 - val_loss: 0.0305\n",
      "Epoch 33/50\n",
      "60/60 - 0s - loss: 0.0034 - val_loss: 0.0299\n",
      "Epoch 34/50\n",
      "60/60 - 0s - loss: 0.0032 - val_loss: 0.0330\n",
      "Epoch 35/50\n",
      "60/60 - 0s - loss: 0.0035 - val_loss: 0.0315\n",
      "Epoch 36/50\n",
      "60/60 - 0s - loss: 0.0032 - val_loss: 0.0319\n",
      "Epoch 37/50\n",
      "60/60 - 0s - loss: 0.0034 - val_loss: 0.0328\n",
      "Epoch 38/50\n",
      "60/60 - 0s - loss: 0.0033 - val_loss: 0.0340\n",
      "Epoch 39/50\n",
      "60/60 - 0s - loss: 0.0033 - val_loss: 0.0345\n",
      "Epoch 40/50\n",
      "60/60 - 0s - loss: 0.0033 - val_loss: 0.0343\n",
      "Epoch 41/50\n",
      "60/60 - 0s - loss: 0.0032 - val_loss: 0.0367\n",
      "Epoch 42/50\n",
      "60/60 - 0s - loss: 0.0033 - val_loss: 0.0356\n",
      "Epoch 43/50\n",
      "60/60 - 0s - loss: 0.0032 - val_loss: 0.0354\n",
      "Epoch 44/50\n",
      "60/60 - 0s - loss: 0.0031 - val_loss: 0.0374\n",
      "Epoch 45/50\n",
      "60/60 - 0s - loss: 0.0033 - val_loss: 0.0371\n",
      "Epoch 46/50\n",
      "60/60 - 0s - loss: 0.0031 - val_loss: 0.0388\n",
      "Epoch 47/50\n",
      "60/60 - 0s - loss: 0.0032 - val_loss: 0.0388\n",
      "Epoch 48/50\n",
      "60/60 - 0s - loss: 0.0031 - val_loss: 0.0403\n",
      "Epoch 49/50\n",
      "60/60 - 0s - loss: 0.0032 - val_loss: 0.0395\n",
      "Epoch 50/50\n",
      "60/60 - 0s - loss: 0.0031 - val_loss: 0.0409\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pacific-medicine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-annex",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "\n",
    "After the model is fit, we can forecast for the entire test dataset.\n",
    "\n",
    "We combine the forecast with the test dataset and invert the scaling. We also invert scaling on the test dataset with the expected pollution numbers.\n",
    "\n",
    "With forecasts and actual values in their original scale, we can then calculate an error score for the model. In this case, we calculate the Root Mean Squared Error (RMSE) that gives error in the same units as the variable itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "muslim-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "attended-helping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5804, 1, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "operating-cyprus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 108.543\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-piano",
   "metadata": {},
   "source": [
    "## Train On Multiple Lag Timesteps\n",
    "\n",
    "The changes needed to train the model on multiple previous time steps are quite minimal, as follows:\n",
    "\n",
    "First, we read the data and prepare it as known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compound-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sought-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "closing-hollow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/siegstedt/binance/data/etheur_2021-01.csv'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('/home/siegstedt','binance','data','etheur_2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "formed-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "filepath = '/home/siegstedt/projects/trading/binance/data/etheur_2020-01_2021-02_1h.csv'\n",
    "data = pd.read_csv(filepath, index_col=0, header=0).drop(columns=[\"datetime\"])\n",
    "data.index.name = \"datetime\"\n",
    "# reorder columns for having closed price accessible at the end of the data frame\n",
    "data = data[['close','open','high','low','volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prescription-inside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       close     open     high      low      volume\n",
      "datetime                                                           \n",
      "2020-01-03 09:00:00    115.4    113.8    115.4    113.8      1.1027\n",
      "2020-01-03 10:00:00   118.46   118.46   118.46   118.46         0.5\n",
      "2020-01-03 11:00:00   118.02   118.06   118.06   118.02     1.33288\n",
      "2020-01-03 12:00:00    118.4    118.4    118.4    118.4     0.08539\n",
      "2020-01-03 13:00:00    118.4    118.4    118.4    118.4         0.0\n",
      "...                      ...      ...      ...      ...         ...\n",
      "2021-02-28 19:00:00  1121.05  1104.73   1128.1   1100.5  2268.75758\n",
      "2021-02-28 20:00:00   1156.0  1121.19  1159.63  1119.37  2217.30903\n",
      "2021-02-28 21:00:00   1170.4  1155.49   1175.4  1150.55  2530.15172\n",
      "2021-02-28 22:00:00   1175.0  1170.29  1183.28  1163.42  2801.53662\n",
      "2021-02-28 23:00:00  1179.39   1175.0  1180.97  1156.75  1292.76135\n"
     ]
    }
   ],
   "source": [
    "# data inspection\n",
    "head = data.head(5)\n",
    "tail = data.tail(5)\n",
    "mid = pd.DataFrame({\"...\":[\"...\" for i in data.columns]}).transpose()\n",
    "mid.columns = data.columns\n",
    "preview = pd.concat([head, mid, tail])\n",
    "preview.index.name = data.index.name\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "specialized-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values\n",
    "values = data.values\n",
    "# ensure that all values are floats\n",
    "values = values.astype('float64')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-killing",
   "metadata": {},
   "source": [
    "Then, you must frame the problem suitably when calling series_to_supervised(). We will use 3 hours of data as input. Also note, we no longer explictly drop the columns from all of the other fields at ob(t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "apart-consumer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10122, 20)\n"
     ]
    }
   ],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 3\n",
    "n_features = 5\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)\n",
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "turned-concern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.016525</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.022112</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>0.015033</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.018622</td>\n",
       "      <td>0.019211</td>\n",
       "      <td>0.014780</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>0.015033</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.018622</td>\n",
       "      <td>0.019211</td>\n",
       "      <td>0.014780</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018622</td>\n",
       "      <td>0.019211</td>\n",
       "      <td>0.014780</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.018862</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.014995</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.018952</td>\n",
       "      <td>0.014522</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>0.637097</td>\n",
       "      <td>0.656484</td>\n",
       "      <td>0.652710</td>\n",
       "      <td>0.628053</td>\n",
       "      <td>0.219140</td>\n",
       "      <td>0.651581</td>\n",
       "      <td>0.636990</td>\n",
       "      <td>0.657553</td>\n",
       "      <td>0.632202</td>\n",
       "      <td>0.244847</td>\n",
       "      <td>0.641128</td>\n",
       "      <td>0.651623</td>\n",
       "      <td>0.652653</td>\n",
       "      <td>0.644615</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>0.651373</td>\n",
       "      <td>0.641284</td>\n",
       "      <td>0.651676</td>\n",
       "      <td>0.642296</td>\n",
       "      <td>0.118446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10121</th>\n",
       "      <td>0.651581</td>\n",
       "      <td>0.636990</td>\n",
       "      <td>0.657553</td>\n",
       "      <td>0.632202</td>\n",
       "      <td>0.244847</td>\n",
       "      <td>0.641128</td>\n",
       "      <td>0.651623</td>\n",
       "      <td>0.652653</td>\n",
       "      <td>0.644615</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>0.651373</td>\n",
       "      <td>0.641284</td>\n",
       "      <td>0.651676</td>\n",
       "      <td>0.642296</td>\n",
       "      <td>0.118446</td>\n",
       "      <td>0.673421</td>\n",
       "      <td>0.651661</td>\n",
       "      <td>0.671558</td>\n",
       "      <td>0.654157</td>\n",
       "      <td>0.115760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10122</th>\n",
       "      <td>0.641128</td>\n",
       "      <td>0.651623</td>\n",
       "      <td>0.652653</td>\n",
       "      <td>0.644615</td>\n",
       "      <td>0.099206</td>\n",
       "      <td>0.651373</td>\n",
       "      <td>0.641284</td>\n",
       "      <td>0.651676</td>\n",
       "      <td>0.642296</td>\n",
       "      <td>0.118446</td>\n",
       "      <td>0.673421</td>\n",
       "      <td>0.651661</td>\n",
       "      <td>0.671558</td>\n",
       "      <td>0.654157</td>\n",
       "      <td>0.115760</td>\n",
       "      <td>0.682505</td>\n",
       "      <td>0.673287</td>\n",
       "      <td>0.681502</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.132093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>0.651373</td>\n",
       "      <td>0.641284</td>\n",
       "      <td>0.651676</td>\n",
       "      <td>0.642296</td>\n",
       "      <td>0.118446</td>\n",
       "      <td>0.673421</td>\n",
       "      <td>0.651661</td>\n",
       "      <td>0.671558</td>\n",
       "      <td>0.654157</td>\n",
       "      <td>0.115760</td>\n",
       "      <td>0.682505</td>\n",
       "      <td>0.673287</td>\n",
       "      <td>0.681502</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.132093</td>\n",
       "      <td>0.685407</td>\n",
       "      <td>0.682618</td>\n",
       "      <td>0.686471</td>\n",
       "      <td>0.681844</td>\n",
       "      <td>0.146262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10124</th>\n",
       "      <td>0.673421</td>\n",
       "      <td>0.651661</td>\n",
       "      <td>0.671558</td>\n",
       "      <td>0.654157</td>\n",
       "      <td>0.115760</td>\n",
       "      <td>0.682505</td>\n",
       "      <td>0.673287</td>\n",
       "      <td>0.681502</td>\n",
       "      <td>0.673755</td>\n",
       "      <td>0.132093</td>\n",
       "      <td>0.685407</td>\n",
       "      <td>0.682618</td>\n",
       "      <td>0.686471</td>\n",
       "      <td>0.681844</td>\n",
       "      <td>0.146262</td>\n",
       "      <td>0.688176</td>\n",
       "      <td>0.685587</td>\n",
       "      <td>0.685014</td>\n",
       "      <td>0.677652</td>\n",
       "      <td>0.067492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10122 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var1(t-2)  \\\n",
       "3       0.016970   0.016525   0.013103   0.022112   0.000058   0.018900   \n",
       "4       0.018900   0.019463   0.015033   0.025041   0.000026   0.018622   \n",
       "5       0.018622   0.019211   0.014780   0.024765   0.000070   0.018862   \n",
       "6       0.018862   0.019425   0.014995   0.025003   0.000004   0.018862   \n",
       "7       0.018862   0.019425   0.014995   0.025003   0.000000   0.018862   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "10120   0.637097   0.656484   0.652710   0.628053   0.219140   0.651581   \n",
       "10121   0.651581   0.636990   0.657553   0.632202   0.244847   0.641128   \n",
       "10122   0.641128   0.651623   0.652653   0.644615   0.099206   0.651373   \n",
       "10123   0.651373   0.641284   0.651676   0.642296   0.118446   0.673421   \n",
       "10124   0.673421   0.651661   0.671558   0.654157   0.115760   0.682505   \n",
       "\n",
       "       var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var1(t-1)  var2(t-1)  \\\n",
       "3       0.019463   0.015033   0.025041   0.000026   0.018622   0.019211   \n",
       "4       0.019211   0.014780   0.024765   0.000070   0.018862   0.019425   \n",
       "5       0.019425   0.014995   0.025003   0.000004   0.018862   0.019425   \n",
       "6       0.019425   0.014995   0.025003   0.000000   0.018862   0.019583   \n",
       "7       0.019583   0.015152   0.025003   0.001894   0.018862   0.019425   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "10120   0.636990   0.657553   0.632202   0.244847   0.641128   0.651623   \n",
       "10121   0.651623   0.652653   0.644615   0.099206   0.651373   0.641284   \n",
       "10122   0.641284   0.651676   0.642296   0.118446   0.673421   0.651661   \n",
       "10123   0.651661   0.671558   0.654157   0.115760   0.682505   0.673287   \n",
       "10124   0.673287   0.681502   0.673755   0.132093   0.685407   0.682618   \n",
       "\n",
       "       var3(t-1)  var4(t-1)  var5(t-1)   var1(t)   var2(t)   var3(t)  \\\n",
       "3       0.014780   0.024765   0.000070  0.018862  0.019425  0.014995   \n",
       "4       0.014995   0.025003   0.000004  0.018862  0.019425  0.014995   \n",
       "5       0.014995   0.025003   0.000000  0.018862  0.019583  0.015152   \n",
       "6       0.015152   0.025003   0.001894  0.018862  0.019425  0.014995   \n",
       "7       0.014995   0.025003   0.000000  0.018351  0.018952  0.014522   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "10120   0.652653   0.644615   0.099206  0.651373  0.641284  0.651676   \n",
       "10121   0.651676   0.642296   0.118446  0.673421  0.651661  0.671558   \n",
       "10122   0.671558   0.654157   0.115760  0.682505  0.673287  0.681502   \n",
       "10123   0.681502   0.673755   0.132093  0.685407  0.682618  0.686471   \n",
       "10124   0.686471   0.681844   0.146262  0.688176  0.685587  0.685014   \n",
       "\n",
       "        var4(t)   var5(t)  \n",
       "3      0.025003  0.000004  \n",
       "4      0.025003  0.000000  \n",
       "5      0.025003  0.001894  \n",
       "6      0.025003  0.000000  \n",
       "7      0.024494  0.000015  \n",
       "...         ...       ...  \n",
       "10120  0.642296  0.118446  \n",
       "10121  0.654157  0.115760  \n",
       "10122  0.673755  0.132093  \n",
       "10123  0.681844  0.146262  \n",
       "10124  0.677652  0.067492  \n",
       "\n",
       "[10122 rows x 20 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "developed-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = reframed.shape[0] - 3 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-nursing",
   "metadata": {},
   "source": [
    "Next, we need to be more careful in specifying the column for input and output.\n",
    "\n",
    "We have 3 * 5 + 5 columns in our framed dataset. We will take 3 * 5 or 15 columns as input for the obs of all features across the previous 3 hours. We will take just the close price variable as output at the following hour, as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-affiliate",
   "metadata": {},
   "source": [
    "Next, we can reshape our input data correctly to reflect the time steps and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aggregate-starter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10050, 15) 10050 (10050,)\n"
     ]
    }
   ],
   "source": [
    "# split into input and outputs\n",
    "n_obs = max(1,n_hours) * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "artificial-mother",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10050, 3, 5) (10050,) (72, 3, 5) (72,)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "timesteps = max(1,n_hours)\n",
    "train_X = train_X.reshape((train_X.shape[0], timesteps, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], timesteps, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-particular",
   "metadata": {},
   "source": [
    "Fitting the model is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "medium-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "intermediate-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "# first layer\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# second layer\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# third layer\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# last layer\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# dense down the net\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile loss\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "intellectual-better",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "140/140 - 10s - loss: 0.0017\n",
      "Epoch 2/50\n",
      "140/140 - 5s - loss: 0.0071\n",
      "Epoch 3/50\n",
      "140/140 - 5s - loss: 0.0080\n",
      "Epoch 4/50\n",
      "140/140 - 5s - loss: 0.0099\n",
      "Epoch 5/50\n",
      "140/140 - 5s - loss: 0.0115\n",
      "Epoch 6/50\n",
      "140/140 - 5s - loss: 0.0145\n",
      "Epoch 7/50\n",
      "140/140 - 5s - loss: 0.0078\n",
      "Epoch 8/50\n",
      "140/140 - 5s - loss: 0.0100\n",
      "Epoch 9/50\n",
      "140/140 - 5s - loss: 0.0205\n",
      "Epoch 10/50\n",
      "140/140 - 5s - loss: 0.0187\n",
      "Epoch 11/50\n",
      "140/140 - 5s - loss: 0.0281\n",
      "Epoch 12/50\n",
      "140/140 - 5s - loss: 0.0466\n",
      "Epoch 13/50\n",
      "140/140 - 5s - loss: 0.0447\n",
      "Epoch 14/50\n",
      "140/140 - 5s - loss: 0.0086\n",
      "Epoch 15/50\n",
      "140/140 - 5s - loss: 0.0067\n",
      "Epoch 16/50\n",
      "140/140 - 5s - loss: 0.0049\n",
      "Epoch 17/50\n",
      "140/140 - 5s - loss: 0.0029\n",
      "Epoch 18/50\n",
      "140/140 - 5s - loss: 0.0031\n",
      "Epoch 19/50\n",
      "140/140 - 5s - loss: 0.0043\n",
      "Epoch 20/50\n",
      "140/140 - 5s - loss: 0.0046\n",
      "Epoch 21/50\n",
      "140/140 - 5s - loss: 0.0051\n",
      "Epoch 22/50\n",
      "140/140 - 5s - loss: 0.0084\n",
      "Epoch 23/50\n",
      "140/140 - 4s - loss: 0.0048\n",
      "Epoch 24/50\n",
      "140/140 - 5s - loss: 0.0047\n",
      "Epoch 25/50\n",
      "140/140 - 5s - loss: 0.0059\n",
      "Epoch 26/50\n",
      "140/140 - 5s - loss: 0.0056\n",
      "Epoch 27/50\n",
      "140/140 - 5s - loss: 0.0043\n",
      "Epoch 28/50\n",
      "140/140 - 4s - loss: 0.0050\n",
      "Epoch 29/50\n",
      "140/140 - 5s - loss: 0.0040\n",
      "Epoch 30/50\n",
      "140/140 - 5s - loss: 0.0035\n",
      "Epoch 31/50\n",
      "140/140 - 4s - loss: 0.0035\n",
      "Epoch 32/50\n",
      "140/140 - 5s - loss: 0.0042\n",
      "Epoch 33/50\n",
      "140/140 - 5s - loss: 0.0041\n",
      "Epoch 34/50\n",
      "140/140 - 5s - loss: 0.0032\n",
      "Epoch 35/50\n",
      "140/140 - 5s - loss: 0.0025\n",
      "Epoch 36/50\n",
      "140/140 - 5s - loss: 0.0020\n",
      "Epoch 37/50\n",
      "140/140 - 5s - loss: 0.0014\n",
      "Epoch 38/50\n",
      "140/140 - 5s - loss: 0.0012\n",
      "Epoch 39/50\n",
      "140/140 - 5s - loss: 9.6463e-04\n",
      "Epoch 40/50\n",
      "140/140 - 5s - loss: 0.0010\n",
      "Epoch 41/50\n",
      "140/140 - 5s - loss: 9.5913e-04\n",
      "Epoch 42/50\n",
      "140/140 - 5s - loss: 0.0010\n",
      "Epoch 43/50\n",
      "140/140 - 5s - loss: 8.8919e-04\n",
      "Epoch 44/50\n",
      "140/140 - 4s - loss: 8.4293e-04\n",
      "Epoch 45/50\n",
      "140/140 - 5s - loss: 8.6258e-04\n",
      "Epoch 46/50\n",
      "140/140 - 5s - loss: 8.9231e-04\n",
      "Epoch 47/50\n",
      "140/140 - 5s - loss: 0.0012\n",
      "Epoch 48/50\n",
      "140/140 - 5s - loss: 0.0011\n",
      "Epoch 49/50\n",
      "140/140 - 5s - loss: 0.0016\n",
      "Epoch 50/50\n",
      "140/140 - 5s - loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18842f71c0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_X, \n",
    "    train_y, \n",
    "    epochs=50,\n",
    "    batch_size=72,\n",
    "    verbose=2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "convertible-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "#history = model.fit(\n",
    "#    train_X, \n",
    "#    train_y, \n",
    "#    epochs=50, \n",
    "#    batch_size=72, \n",
    "#    validation_data=(test_X, test_y),\n",
    "#    verbose=2,\n",
    "#    shuffle=False\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "partial-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot history\n",
    "#pyplot.plot(history.history['loss'], label='train')\n",
    "#pyplot.plot(history.history['val_loss'], label='test')\n",
    "#pyplot.legend()\n",
    "#pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "northern-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], max(1,n_hours)*n_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-purchase",
   "metadata": {},
   "source": [
    "The only other small change is in how to evaluate the model. Specifically, in how we reconstruct the rows with 8 columns suitable for reversing the scaling operation to get the y and yhat back into the original scale so that we can calculate the RMSE.\n",
    "\n",
    "The gist of the change is that we concatenate the y or yhat column with the last 7 features of the test dataset in order to inverse the scaling, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "present-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecast\n",
    "n_inverted = n_features - 1\n",
    "inv_yhat = concatenate((yhat, test_X[:, -n_inverted:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -n_inverted:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "opened-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 351.587\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "early-mexico",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inspect the time series\n",
    "past = {\n",
    "    \"real\": data.close.iloc[:n_train_hours].tail(50).to_list(),\n",
    "    \"pred\": [np.nan for i in range(50)]\n",
    "}\n",
    "predicted = {\n",
    "    \"real\": inv_y,\n",
    "    \"pred\": inv_yhat,\n",
    "}\n",
    "\n",
    "check = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(past),\n",
    "        pd.DataFrame(predicted)\n",
    "    ]\n",
    ").reset_index(drop=True)\n",
    "check.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "funded-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "      <th>rel_diff_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1312.35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-99.923801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1223.41</td>\n",
       "      <td>1581.821783</td>\n",
       "      <td>29.296130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1222.98</td>\n",
       "      <td>1577.909361</td>\n",
       "      <td>29.021682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1215.36</td>\n",
       "      <td>1573.917289</td>\n",
       "      <td>29.502147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1226.29</td>\n",
       "      <td>1570.147917</td>\n",
       "      <td>28.040506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1230.38</td>\n",
       "      <td>1566.807883</td>\n",
       "      <td>27.343413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1241.43</td>\n",
       "      <td>1564.332195</td>\n",
       "      <td>26.010504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1198.30</td>\n",
       "      <td>1563.131673</td>\n",
       "      <td>30.445771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1209.49</td>\n",
       "      <td>1563.291163</td>\n",
       "      <td>29.252095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1179.55</td>\n",
       "      <td>1564.060174</td>\n",
       "      <td>32.598039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1201.94</td>\n",
       "      <td>1563.742138</td>\n",
       "      <td>30.101514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       real         pred  rel_diff_%\n",
       "49  1312.35     1.000000  -99.923801\n",
       "50  1223.41  1581.821783   29.296130\n",
       "51  1222.98  1577.909361   29.021682\n",
       "52  1215.36  1573.917289   29.502147\n",
       "53  1226.29  1570.147917   28.040506\n",
       "54  1230.38  1566.807883   27.343413\n",
       "55  1241.43  1564.332195   26.010504\n",
       "56  1198.30  1563.131673   30.445771\n",
       "57  1209.49  1563.291163   29.252095\n",
       "58  1179.55  1564.060174   32.598039\n",
       "59  1201.94  1563.742138   30.101514"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[\"rel_diff_%\"] = (check.pred - check.real) / check.real * 100\n",
    "check.iloc[49:60,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "physical-sessions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-06 15:36:47.369264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Reframed data shape: (10101, 125)\n",
      "(10029, 120) 10029 (10029,)\n",
      "(10029, 24, 5) (10029,) (72, 24, 5) (72,)\n",
      "2021-04-06 15:36:48.061674: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-06 15:36:48.062190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-04-06 15:36:48.097353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-04-06 15:36:48.097699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:0a:00.0 name: GeForce GTX 1660 computeCapability: 7.5\n",
      "coreClock: 1.83GHz coreCount: 22 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 178.86GiB/s\n",
      "2021-04-06 15:36:48.097719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-04-06 15:36:48.099238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-04-06 15:36:48.099268: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-04-06 15:36:48.099798: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-04-06 15:36:48.099933: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-04-06 15:36:48.100012: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
      "2021-04-06 15:36:48.100339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-04-06 15:36:48.100383: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-04-06 15:36:48.100390: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-04-06 15:36:48.100613: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-04-06 15:36:48.100905: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-04-06 15:36:48.100923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-04-06 15:36:48.100928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2021-04-06 15:36:48.580043: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-04-06 15:36:48.580375: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3593255000 Hz\n",
      "Epoch 1/50\n",
      "140/140 - 8s - loss: 0.0022\n",
      "Epoch 2/50\n",
      "140/140 - 5s - loss: 0.0078\n",
      "Epoch 3/50\n",
      "140/140 - 5s - loss: 0.0081\n",
      "Epoch 4/50\n",
      "140/140 - 5s - loss: 0.0105\n",
      "Epoch 5/50\n",
      "140/140 - 5s - loss: 0.0134\n",
      "Epoch 6/50\n",
      "140/140 - 5s - loss: 0.0159\n",
      "Epoch 7/50\n",
      "140/140 - 5s - loss: 0.0215\n",
      "Epoch 8/50\n",
      "140/140 - 5s - loss: 0.0465\n",
      "Epoch 9/50\n",
      "140/140 - 5s - loss: 0.0261\n",
      "Epoch 10/50\n",
      "140/140 - 5s - loss: 0.0406\n",
      "Epoch 11/50\n",
      "140/140 - 5s - loss: 0.0678\n",
      "Epoch 12/50\n",
      "140/140 - 5s - loss: 0.0567\n",
      "Epoch 13/50\n",
      "140/140 - 5s - loss: 0.0539\n",
      "Epoch 14/50\n",
      "140/140 - 5s - loss: 0.0533\n",
      "Epoch 15/50\n",
      "140/140 - 5s - loss: 0.0520\n",
      "Epoch 16/50\n",
      "140/140 - 5s - loss: 0.0517\n",
      "Epoch 17/50\n",
      "140/140 - 5s - loss: 0.0514\n",
      "Epoch 18/50\n",
      "140/140 - 5s - loss: 0.0511\n",
      "Epoch 19/50\n",
      "140/140 - 5s - loss: 0.0507\n",
      "Epoch 20/50\n",
      "140/140 - 5s - loss: 0.0503\n",
      "Epoch 21/50\n",
      "140/140 - 5s - loss: 0.0504\n",
      "Epoch 22/50\n",
      "140/140 - 5s - loss: 0.0509\n",
      "Epoch 23/50\n",
      "140/140 - 5s - loss: 0.0504\n",
      "Epoch 24/50\n",
      "140/140 - 5s - loss: 0.0502\n",
      "Epoch 25/50\n",
      "140/140 - 5s - loss: 0.0499\n",
      "Epoch 26/50\n",
      "140/140 - 5s - loss: 0.0499\n",
      "Epoch 27/50\n",
      "140/140 - 5s - loss: 0.0497\n",
      "Epoch 28/50\n",
      "140/140 - 5s - loss: 0.0484\n",
      "Epoch 29/50\n",
      "140/140 - 5s - loss: 0.0501\n",
      "Epoch 30/50\n",
      "140/140 - 5s - loss: 0.0488\n",
      "Epoch 31/50\n",
      "140/140 - 5s - loss: 0.0497\n",
      "Epoch 32/50\n",
      "140/140 - 5s - loss: 0.0492\n",
      "Epoch 33/50\n",
      "140/140 - 5s - loss: 0.0490\n",
      "Epoch 34/50\n",
      "140/140 - 5s - loss: 0.0488\n",
      "Epoch 35/50\n",
      "140/140 - 5s - loss: 0.0487\n",
      "Epoch 36/50\n",
      "140/140 - 5s - loss: 0.0487\n",
      "Epoch 37/50\n",
      "140/140 - 5s - loss: 0.0486\n",
      "Epoch 38/50\n",
      "140/140 - 5s - loss: 0.0486\n",
      "Epoch 39/50\n",
      "140/140 - 5s - loss: 0.0486\n",
      "Epoch 40/50\n",
      "140/140 - 5s - loss: 0.0486\n",
      "Epoch 41/50\n",
      "140/140 - 5s - loss: 0.0486\n",
      "Epoch 42/50\n",
      "140/140 - 5s - loss: 0.0486\n",
      "Epoch 43/50\n",
      "140/140 - 5s - loss: 0.0486\n",
      "Epoch 44/50\n",
      "140/140 - 5s - loss: 0.0485\n",
      "Epoch 45/50\n",
      "140/140 - 5s - loss: 0.0133\n",
      "Epoch 46/50\n",
      "140/140 - 5s - loss: 0.0189\n",
      "Epoch 47/50\n",
      "140/140 - 5s - loss: 0.0211\n",
      "Epoch 48/50\n",
      "140/140 - 5s - loss: 0.0162\n",
      "Epoch 49/50\n",
      "140/140 - 5s - loss: 0.0702\n",
      "Epoch 50/50\n",
      "140/140 - 5s - loss: 0.0649\n",
      "Test RMSE: 718.801\n",
      "Traceback (most recent call last):\n",
      "  File \"binance/src/lstm_run.py\", line 259, in <module>\n",
      "    main()\n",
      "  File \"binance/src/lstm_run.py\", line 226, in main\n",
      "    \"real\": data.close.iloc[:n_train_hours].tail(50).to_list(),\n",
      "NameError: name 'data' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python binance/src/lstm_run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-cornwall",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
